{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a0f04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "274efb7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/julioberrocal/Desktop/Classes/Winter 2024/Advanced Programming/Final Project/Muffintown_Final/Query.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of non-compliant observations is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(non_compliant_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpct_non_compliant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m percent.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 35\u001b[0m initial_df \u001b[38;5;241m=\u001b[39m prepare_df()\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mprepare_df\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_df\u001b[39m():\n\u001b[1;32m      3\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/julioberrocal/Desktop/Classes/Winter 2024/Advanced Programming/Final Project/Muffintown_Final/Query.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_path)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Converting the SKU into a String object\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent Job\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent Job\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, engine\u001b[38;5;241m=\u001b[39mengine)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1497\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1498\u001b[0m     )\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1503\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1372\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/julioberrocal/Desktop/Classes/Winter 2024/Advanced Programming/Final Project/Muffintown_Final/Query.xlsx'"
     ]
    }
   ],
   "source": [
    "def prepare_df():\n",
    "\n",
    "    file_path = '/Users/julioberrocal/Desktop/Classes/Winter 2024/Advanced Programming/Final Project/Muffintown_Final/Query.xlsx'\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Converting the SKU into a String object\n",
    "    df['Current Job'] = df['Current Job'].astype(str)\n",
    "\n",
    "    # Converting columns to Datetime object\n",
    "    df['Start of Batch Date/Time'] = pd.to_datetime(df['Start of Batch Date/Time'])\n",
    "    df['End of Batch Date/Time'] = pd.to_datetime(df['End of Batch Date/Time'])\n",
    "\n",
    "    # Calculating the batch length in hours\n",
    "    df['Batch Length (Hours)'] = (df['End of Batch Date/Time'] - df['Start of Batch Date/Time']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Creating Units per Hour Column\n",
    "    df['Units Per Hour'] = df['Batch Count'] / df['Batch Length (Hours)']\n",
    "\n",
    "    # Remove rows with missing values in 'Optimal Cases Per Hour' column\n",
    "    df.dropna(subset=['Optimal Cases Per Hour'], inplace=True)\n",
    "\n",
    "    compliant_df = df[(df['Units Per Hour'] >= df['Lower Target']) & (df['Units Per Hour'] <= df['Upper Target'])]\n",
    "    non_compliant_df = df[(df['Units Per Hour'] < df['Lower Target']) | (df['Units Per Hour'] > df['Upper Target'])]\n",
    "\n",
    "    total_observations = len(df)\n",
    "    print(total_observations)\n",
    "    pct_compliant = 100 * round(len(compliant_df)/total_observations,2)\n",
    "    pct_non_compliant = 100 * round(len(non_compliant_df)/total_observations,2)\n",
    "\n",
    "    print(f'The number of compliant observations is: {len(compliant_df)} or {pct_compliant} percent.')\n",
    "    print(f'The number of non-compliant observations is: {len(non_compliant_df)} or {pct_non_compliant} percent.')\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = prepare_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "547f8625",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m analysis_results\n\u001b[1;32m     43\u001b[0m skus \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m96605\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m24970\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 44\u001b[0m sku_results \u001b[38;5;241m=\u001b[39m analyze_sku(initial_df, skus)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m sku_results:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initial_df' is not defined"
     ]
    }
   ],
   "source": [
    "def analyze_sku(df, skus):\n",
    "    analysis_results = []\n",
    "    \n",
    "    for sku in skus:\n",
    "\n",
    "        # Filter by the current SKU\n",
    "        filtered_df = df[df['Current Job'] == sku]\n",
    "        \n",
    "        # Number of records for the SKU\n",
    "        records = len(filtered_df)\n",
    "        \n",
    "        # Percentage of compliant records for the SKU\n",
    "        compliant_records = len(filtered_df[(filtered_df['Units Per Hour'] >= filtered_df['Lower Target']) & \n",
    "                                                (filtered_df['Units Per Hour'] <= filtered_df['Upper Target'])])\n",
    "        \n",
    "        compliance_percentage = round((compliant_records / records),2) * 100 if records != 0 else 0\n",
    "        \n",
    "        # Average units per hour of the SKU\n",
    "        avg_units_per_hour = round(filtered_df['Units Per Hour'].mean(),2)\n",
    "        \n",
    "        # Standard deviation of units per hour of the SKU\n",
    "        stdev_units_per_hour = round(filtered_df['Units Per Hour'].std(),2)\n",
    "\n",
    "        # Plot histogram of units per hour for the SKU\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.hist(filtered_df['Units Per Hour'], bins=20, color='skyblue', edgecolor='black')\n",
    "        plt.title(f'Units Per Hour Distribution for SKU: {sku}')\n",
    "        plt.xlabel('Units Per Hour')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'{sku}_histogram.png')\n",
    "\n",
    "        analysis_results.append({\n",
    "            'SKU': sku,\n",
    "            'Number of Records': records,\n",
    "            'Percentage of Compliant Records': compliance_percentage,\n",
    "            'Average Units Per Hour': avg_units_per_hour,\n",
    "            'Standard Deviation of Units Per Hour': stdev_units_per_hour\n",
    "        })\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "skus = ['96605', '24970']\n",
    "sku_results = analyze_sku(initial_df, skus)\n",
    "for result in sku_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12d86afc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m analysis_results\n\u001b[1;32m     24\u001b[0m group_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAWRENCE AUTOBAKE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAWRENCE - SW PACK\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m group_results \u001b[38;5;241m=\u001b[39m analyze_group(initial_df, group_names)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m group_results:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initial_df' is not defined"
     ]
    }
   ],
   "source": [
    "def analyze_group(df, group_names):\n",
    "    analysis_results = []\n",
    "    \n",
    "    for group_name in group_names:\n",
    "        # Filter by the current Group Name\n",
    "        filtered_df = df[df['Group Name'] == group_name]\n",
    "        \n",
    "        # Number of records for the Group Name\n",
    "        records = len(filtered_df)\n",
    "        \n",
    "        # Percentage of compliant records for the Group Name\n",
    "        compliant_records = len(filtered_df[(filtered_df['Units Per Hour'] >= filtered_df['Lower Target']) & \n",
    "                                                (filtered_df['Units Per Hour'] <= filtered_df['Upper Target'])])\n",
    "        compliance_percentage = round((compliant_records / records),2) * 100 if records != 0 else 0\n",
    "        \n",
    "        analysis_results.append({\n",
    "            'Group Name': group_name,\n",
    "            'Number of Records': records,\n",
    "            'Percentage of Compliant Records': compliance_percentage,\n",
    "        })\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "group_names = ['LAWRENCE AUTOBAKE', 'LAWRENCE - SW PACK']\n",
    "group_results = analyze_group(initial_df, group_names)\n",
    "for result in group_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb796288",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m skus \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m96605\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m24970\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     36\u001b[0m group_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAWRENCE AUTOBAKE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAWRENCE - SW PACK\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m analysis_results \u001b[38;5;241m=\u001b[39m analyze_sku_and_group(initial_df, skus, group_names)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m analysis_results:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initial_df' is not defined"
     ]
    }
   ],
   "source": [
    "def analyze_sku_and_group(df, skus, group_names):\n",
    "    analysis_results = []\n",
    "    \n",
    "    for sku in skus:\n",
    "        for group_name in group_names:\n",
    "            # Filter by the current SKU and Group Name\n",
    "            filtered_df = df[(df['Current Job'] == sku) & (df['Group Name'] == group_name)]\n",
    "            \n",
    "            # Number of records for the SKU and Group Name combination\n",
    "            num_records = len(filtered_df)\n",
    "            \n",
    "            # Percentage of compliant records for the SKU and Group Name combination\n",
    "            num_compliant_records = len(filtered_df[(filtered_df['Units Per Hour'] >= filtered_df['Lower Target']) & \n",
    "                                                    (filtered_df['Units Per Hour'] <= filtered_df['Upper Target'])])\n",
    "            \n",
    "            compliance_pct = round((num_compliant_records / num_records) * 100,2) if num_records != 0 else 0\n",
    "            \n",
    "            # Average units per hour of the SKU and Group Name combination\n",
    "            avg_units_per_hour = round(filtered_df['Units Per Hour'].mean(),2)\n",
    "            \n",
    "            # Standard deviation of units per hour of the SKU and Group Name combination\n",
    "            stdev_units_per_hour = round(filtered_df['Units Per Hour'].std(),2)\n",
    "            \n",
    "            analysis_results.append({\n",
    "                'SKU': sku,\n",
    "                'Group Name': group_name,\n",
    "                'Number of Records': num_records,\n",
    "                'Percentage of Compliant Records': compliance_pct,\n",
    "                'Average Units Per Hour': avg_units_per_hour,\n",
    "                'Standard Deviation of Units Per Hour': stdev_units_per_hour\n",
    "            })\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "skus = ['96605', '24970']\n",
    "group_names = ['LAWRENCE AUTOBAKE', 'LAWRENCE - SW PACK']\n",
    "analysis_results = analyze_sku_and_group(initial_df, skus, group_names)\n",
    "\n",
    "for result in analysis_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "492c98d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdurrahman/anaconda3/lib/python3.11/site-packages/gradio/utils.py:857: UserWarning: Expected 0 arguments for function <function process_data at 0x28f3b1440>, received 2.\n",
      "  warnings.warn(\n",
      "/Users/abdurrahman/anaconda3/lib/python3.11/site-packages/gradio/utils.py:865: UserWarning: Expected maximum 0 arguments for function <function process_data at 0x28f3b1440>, received 2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7887\n",
      "Running on public URL: https://4cf16884b1c3bfd2a2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4cf16884b1c3bfd2a2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_data():\n",
    "    return \"ToDo\"\n",
    "\n",
    "def upload_file(files):\n",
    "    file_paths = [file.name for file in files]\n",
    "    return file_paths\n",
    "\n",
    "tab_search = gr.Interface(\n",
    "    inputs = [gr.Textbox(label=\"SKU\"), gr.Textbox(label=\"Factory\")],\n",
    "    outputs = [gr.Textbox(label=\"Records\"), gr.Textbox(label=\"Compliance\"),gr.Textbox(label=\"Avg Units/Hr\"), gr.Textbox(label=\"Std Dev\"), gr.BarPlot(label=\"Graph\")],\n",
    "    fn = process_data\n",
    ")\n",
    "\n",
    "with gr.Blocks() as tab_files:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            file_output = gr.File()\n",
    "            upload_button = gr.UploadButton(\"Click to Upload Reference File\", file_types=[\"files\"])\n",
    "            upload_button.upload(upload_file, upload_button, file_output)\n",
    "        with gr.Column():\n",
    "            file_output = gr.File()\n",
    "            upload_button = gr.UploadButton(\"Click to Upload Template File\", file_types=[\"files\"])\n",
    "            upload_button.upload(upload_file, upload_button, file_output)\n",
    "            \n",
    "    \n",
    "demo = gr.TabbedInterface([tab_files, tab_search], [\"Upload Files\", \"Search\"])\n",
    "\n",
    "#demo.launch(share=True, auth=(\"BrianA\", \"Brian@Muffintown1\"))\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e705a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
